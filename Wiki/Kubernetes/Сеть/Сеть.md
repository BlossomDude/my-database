Важная составляющая нашего кластера это сеть. Без сети мы бы не смогли отправлять запросы к kube-apiserver, мы не могли бы получить доступ к подам и так далее.

Каждый узел, в том числе мастер - должен иметь минимум один настроенный сетевой интерфейс для общения, а так же порты для общения наших компонентов.


| Component               | port        |
| ----------------------- | ----------- |
| kube-apiserver          | 6443        |
| kube-scheduler          | 10259       |
| kube-controller-manager | 10257       |
| etcd                    | 2379, 2380  |
| kubelet                 | 10250       |
| worker-nodes            | 30000-32767 |
[google.com](https://google.com)
## CNI 
Плагины CNI хранятся на мастер узле в директории:
`/opt/bin/cni/`

Конфигурация плагинов находится в директории:
`/etc/cni/net.d/`
Файл конфигурации выбирается в алфавитном порядке.

Пример файла конфигурации:
```json
{
    "cniVersion": "1.1.0",
    "name": "dbnet",
    "type": "bridge",
    "bridge": "cni0",
    "keyA": ["some more", "plugin specific", "configuration"],
    "ipam": {
        "type": "host-local",
        "subnet": "10.1.0.0/16",
        "gateway": "10.1.0.1"
    },
    "dns": {
        "nameservers": [ "10.1.0.1" ]
    }
}
```

- `cniVersion: "1.1.0"` — указывает версию спецификации CNI, используемую в этой конфигурации. Важно для обеспечения совместимости между CNI-плагинами и инфраструктурой.
- `name: dbnet` — уникальное имя сети, которое будет использоваться для идентификации.
    - Это имя помогает различать разные сети в одной системе.
- `type: "bridge"` — тип плагина. Указывает, что сеть будет создаваться с использованием мостового интерфейса.
- `bridge: "cni0"` — имя мостового интерфейса на хосте, который создаст плагин.
    - Если интерфейс `cni0` уже существует, плагин будет использовать его.
- `keyA: ["some more", "plugin specific", "configuration"]` — дополнительная, специфичная для плагина конфигурация.
    - Она позволяет передавать кастомные параметры, которые может обрабатывать только данный плагин.
- **`ipam`** (IP Address Management):
    - Настройки управления IP-адресами для этой сети.
        - **`type`**: `"host-local"` — локальное управление IP-адресами, где адреса хранятся на хосте.
        - **`subnet`**: `"10.1.0.0/16"` — диапазон IP-адресов, доступный для выделения контейнерам.
        - **`gateway`**: `"10.1.0.1"` — IP-адрес шлюза для этой сети. Все внешние пакеты будут проходить через этот адрес.
- `dns: nameservers`:
        - `["10.1.0.1"]` — адрес DNS-сервера, который будет использоваться контейнерами для разрешения доменных имен.

##### Weave
- На каждом узле назначает своего агента
- По умолчанию выдает ip в диапазоне 10.32.0.0/12

## CoreDNS

По умолчанию в кластере работает встроенный CoreDNS.

- При создании [[Service]] - создается DNS-запись. Таким образом дает возможность всем подам в кластере достучаться до пода с сервисом.
- Если мы обратимся от одного пода к другому в рамках одного неймспейса то мы можем обратится по имени сервиса так: `curl http://web-server`. Но если под находится в другом неймспейсе, то это нужно указать явно: `curl http://web-service.blue`
Пример таблицы DNS:

| hostname    | namespace | type | root          | IP            |
| ----------- | --------- | ---- | ------------- | ------------- |
| web-service | blue      | svc  | cluster.local | 10.107.37.188 |
| 10-244-4-5  | blue      | pod  | cluster.local | 10.244.4.5    |
Для пода автоматически назначается имя - ip адрес с заменой точек на дефисы.

`CoreDNS` - является сервером dns по умолчанию начиная с версии 1.12. Он работает как под (Он находится в deployment и replica set).

Для работы CoreDNS требуется файл конфигурации. Он находится в `/etc/coredns/Corefile` И передается в под CoreDNS в виде [[ConfigMap & Secret|ConfigMap]]:
```
.:53 {
	errors
	health
	kubernetes cluster.local in-addr.arpa ip6.arpa {
		pods insecure
		updtream
		falltrough in-addr.arpa ip6.arpa
	}
	prometheus :9153
	proxy . /etc/resolv.conf
	cache 30
	reload
}
```
Он содержит плагины для обработки ошибок, мониторинга, кэширования и тд.
Для работы с k8s он содержит соответствующий плагин - kubernetes.
- В данном примере `cluster.local` указан как доменное имя верхнего уровня. таким образом каждая запись на сервере CoreDNS попадает под этот домен.
- `pods insecure` - включает преобразования  ip пода в hostname заменяя точки на дефисы.
>[! info] 
>Плагин `proxy` в файле конфигурации:
>Любая запись которую DNS сервер не сможет разрешить, например если под решил достучаться до гугла. Он перенаправляется на `nameserver` в файле `/etc/resolv.conf` находящийся в контейнере самого CoreDNS 

При запуске CoreDNS создается [[Service]] kube-dns - Ip-адрес которого является dns-сервером по умолчанию для каждого созданного пода в клaстере. За это отвечает [[kubelet]]

Kubernetes ресурсы нужные coreDNS:

1. _a service account named_ **_coredns_**_,_
2. _cluster-roles named_ **_coredns_** _and_ **_kube-dns_**
3. _clusterrolebindings named_ **_coredns_** _and_ **_kube-dns_**_,_ 
4. _a deployment named_ **_coredns_**_,_
5. _a configmap named_ **_coredns_** _and a_
6. _service named_ **_kube-dns_**_._