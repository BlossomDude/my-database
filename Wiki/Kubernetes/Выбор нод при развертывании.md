---
Owner: Blossom Dude
Last edited time: 2024-05-26T16:51
Created time: 2024-05-26T16:36
---
- **==NodeSelector==** - простой но не очень гибки метод выбора нод для развертывывании на нем объектов k8s
    
    ```YAML
    apiVersion: apps/v1
    kind: deployment
    metadata:
    	name: nginx
    spec:
    	...
    	template:
    	...
    	spec:
    	...
    	nodeSelector:
    		disktype: ssd        # Выбор нод только с селектором ssd
    ```
    
      
    
- **==Affinity Anti-affinity==**
    
    ==В Kubernetes,== ==**affinity**== ==и== ==**anti-affinity**== – это механизмы, которые позволяют вам влиять на то, как поды распределяются по узлам в кластере. Они используются для оптимизации размещения подов с учетом различных факторов, таких как производительность, доступность и стоимость ресурсов.
    
      
    
    ==**Affinity**== (сродство) позволяет указать правила, которые привлекают поды к определенным узлам. Например, вы можете захотеть разместить поды ближе друг к другу для улучшения производительности сети или для того, чтобы они были на узлах с определенными аппаратными характеристиками.
    
    ==**Anti-affinity**== (антисродство), наоборот, позволяет указать правила, которые отталкивают поды от определенных узлов. Это может быть полезно для обеспечения высокой доступности, размещая поды таким образом, чтобы они не были сосредоточены на одном узле, что может предотвратить одновременный отказ всех подов при проблемах с узлом.
    
    Примеры использования этих параметров в манифесте пода:
    
    ```YAML
    apiVersion: v1
    kind: Pod
    metadata:
      name: mypod
    spec:
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: "disktype"
                operator: "In"
                values:
                - "ssd"
      antiAffinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            labelSelector:
              matchExpressions:
              - key: "app"
                operator: "In"
                values:
                - "myapp"
            topologyKey: "kubernetes.io/hostname"
    ```
    
    В этом примере `nodeAffinity` используется для указания, что под предпочтительно должен быть запланирован на узлы с SSD дисками. В то же время `podAntiAffinity` используется для того, чтобы поды с меткой `app=myapp` не были размещены на одном и том же узле, что обеспечивает их разделение для повышения доступности.
    
      
    
- **==Taints Toleration==**
    
    **==Taints==** — это особые политики, которые присваиваются узлам в группе. С помощью taint-политик можно запретить некоторым подам выполняться на определенных узлах. Например, можно указать, что поды для рендеринга должны запускаться только на [узлах с GPU](https://yandex.cloud/ru/docs/managed-kubernetes/concepts/node-group/node-group-gpu).  
      
      
    ==Преимущества использования taint-политик:==
    
    - политики сохраняются, когда узел перезапускается или заменяется новым;
    - при добавлении узлов в группу политики назначаются этому узлу автоматически;
    - политики автоматически назначаются новым узлам при [масштабировании группы узлов](https://yandex.cloud/ru/docs/managed-kubernetes/concepts/autoscale).
    
    Каждая taint-политика состоит из трех частей: `<ключ> = <значение>:<эффект>`
    
    Список доступных taint-эффектов:
    
    - `NO_SCHEDULE` — запретить запуск новых подов на узлах группы (уже запущенные поды продолжат работу);
    - `PREFER_NO_SCHEDULE` — избегать запуска подов на узлах группы, если для запуска этих подов есть свободные ресурсы в других группах;
    - `NO_EXECUTE` — завершить работу подов на узлах этой группы, расселить их в другие группы, а запуск новых подов запретить.
    
    ==**_Tolerations_**== — это исключения из taint-политик. С помощью tolerations можно разрешить определенным подам работать на узлах, даже если taint-политика группы узлов препятствует этому.
    
    Например, если для узлов в группе настроена taint-политика `key1=value1:NoSchedule`, разместить поды на таком узле можно с помощью tolerations:
    
    `apiVersion: v1 kind: Pod ... spec: ... tolerations: - key: "key1" operator: "Equal" value: "value1" effect: "NoSchedule"`
    
    **Примечание**
    
    Для системных подов автоматически назначаются tolerations, позволяющие им работать на всех доступных узлах.